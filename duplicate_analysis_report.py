"""
é‡å¤åº¦åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆå®Œæ•´çš„é‡å¤æ£€æµ‹åˆ†ææŠ¥å‘Š
"""
import sqlite3
import json
from datetime import datetime

def generate_duplicate_analysis_report():
    """ç”Ÿæˆé‡å¤åº¦åˆ†ææŠ¥å‘Š"""
    print("=== é‡å¤åº¦åˆ†ææŠ¥å‘Š ===")
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect('data/analysis_results.db')
    cursor = conn.cursor()
    
    # è·å–æ€»ä½“ç»Ÿè®¡
    cursor.execute('SELECT COUNT(*) FROM sentiment_results')
    total_records = cursor.fetchone()[0]
    
    cursor.execute('SELECT COUNT(*) FROM sentiment_results WHERE duplication_rate = 0')
    unique_records = cursor.fetchone()[0]
    
    cursor.execute('SELECT COUNT(*) FROM sentiment_results WHERE duplication_rate > 0')
    duplicate_records = cursor.fetchone()[0]
    
    cursor.execute('SELECT COUNT(*) FROM sentiment_results WHERE duplication_rate >= 0.75')
    high_duplicate_records = cursor.fetchone()[0]
    
    cursor.execute('SELECT AVG(duplication_rate) FROM sentiment_results WHERE duplication_rate > 0')
    avg_duplicate_rate = cursor.fetchone()[0] or 0
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»è®°å½•æ•°: {total_records}")
    print(f"  å”¯ä¸€è®°å½•: {unique_records} ({unique_records/total_records*100:.1f}%)")
    print(f"  æœ‰é‡å¤è®°å½•: {duplicate_records} ({duplicate_records/total_records*100:.1f}%)")
    print(f"  é«˜é‡å¤åº¦è®°å½• (â‰¥75%): {high_duplicate_records} ({high_duplicate_records/total_records*100:.1f}%)")
    print(f"  é‡å¤è®°å½•å¹³å‡é‡å¤åº¦: {avg_duplicate_rate:.1f}%")
    
    # é‡å¤åº¦åˆ†å¸ƒ
    print(f"\nğŸ“ˆ é‡å¤åº¦åˆ†å¸ƒ:")
    ranges = [
        ("å”¯ä¸€ (0%)", 0.0, 0.0),
        ("ä½é‡å¤ (1-50%)", 0.01, 0.5),
        ("ä¸­é‡å¤ (51-75%)", 0.51, 0.75),
        ("é«˜é‡å¤ (76-90%)", 0.76, 0.9),
        ("æé«˜é‡å¤ (91-100%)", 0.91, 1.0)
    ]
    
    for range_name, min_val, max_val in ranges:
        if min_val == max_val:
            cursor.execute('SELECT COUNT(*) FROM sentiment_results WHERE duplication_rate = ?', (min_val,))
        else:
            cursor.execute('SELECT COUNT(*) FROM sentiment_results WHERE duplication_rate >= ? AND duplication_rate <= ?', (min_val, max_val))
        count = cursor.fetchone()[0]
        percentage = (count / total_records) * 100 if total_records > 0 else 0
        print(f"  {range_name}: {count} æ¡ ({percentage:.1f}%)")
    
    # é«˜é‡å¤åº¦æ¡ˆä¾‹è¯¦ç»†åˆ†æ
    cursor.execute('''
        SELECT id, title, duplication_rate, publish_time, content
        FROM sentiment_results 
        WHERE duplication_rate >= 0.75 
        ORDER BY duplication_rate DESC
    ''')
    high_dup_records = cursor.fetchall()
    
    if high_dup_records:
        print(f"\nğŸ” é«˜é‡å¤åº¦æ¡ˆä¾‹åˆ†æ:")
        
        for record in high_dup_records:
            record_id, title, dup_rate, publish_time, content = record
            print(f"\n  ğŸ“‹ è®°å½• ID {record_id}:")
            print(f"     æ ‡é¢˜: {title}")
            print(f"     é‡å¤åº¦: {dup_rate*100:.1f}%")
            print(f"     å‘å¸ƒæ—¶é—´: {publish_time}")
            
            # åˆ†æå†…å®¹ç‰¹å¾
            if content:
                content_preview = content[:100].replace('\n', ' ').replace('\r', ' ')
                print(f"     å†…å®¹é¢„è§ˆ: {content_preview}...")
                
                # åˆ†ææ˜¯å¦ä¸ºHTMLå†…å®¹
                if content.strip().startswith('<!doctype') or content.strip().startswith('<html'):
                    print(f"     å†…å®¹ç±»å‹: HTMLæ ¼å¼")
                elif 'http' in content.lower():
                    print(f"     å†…å®¹ç±»å‹: åŒ…å«é“¾æ¥")
                else:
                    print(f"     å†…å®¹ç±»å‹: çº¯æ–‡æœ¬")
    
    # æŸ¥æ‰¾å…·ä½“çš„é‡å¤å¯¹
    print(f"\nğŸ”— é‡å¤æ–‡æœ¬å¯¹åˆ†æ:")
    
    # é€šè¿‡é‡å¤åº¦æ‰¾åˆ°é…å¯¹çš„æ–‡æœ¬
    cursor.execute('''
        SELECT r1.id, r1.title, r1.duplication_rate, r1.publish_time,
               r2.id, r2.title, r2.duplication_rate, r2.publish_time
        FROM sentiment_results r1
        JOIN sentiment_results r2 ON r1.duplication_rate = r2.duplication_rate 
        WHERE r1.duplication_rate >= 0.75 AND r1.id < r2.id
        ORDER BY r1.duplication_rate DESC
    ''')
    
    duplicate_pairs = cursor.fetchall()
    
    if duplicate_pairs:
        for i, pair in enumerate(duplicate_pairs, 1):
            id1, title1, rate1, time1, id2, title2, rate2, time2 = pair
            print(f"\n  {i}. é‡å¤å¯¹ (ç›¸ä¼¼åº¦: {rate1*100:.1f}%):")
            print(f"     æ–‡æœ¬A: ID {id1} - {title1}")
            print(f"     æ—¶é—´A: {time1}")
            print(f"     æ–‡æœ¬B: ID {id2} - {title2}")
            print(f"     æ—¶é—´B: {time2}")
            
            # è®¡ç®—æ—¶é—´å·®
            try:
                time1_obj = datetime.strptime(time1, '%Y-%m-%d %H:%M:%S')
                time2_obj = datetime.strptime(time2, '%Y-%m-%d %H:%M:%S')
                time_diff = abs((time2_obj - time1_obj).total_seconds() / 3600)  # å°æ—¶
                print(f"     æ—¶é—´é—´éš”: {time_diff:.1f} å°æ—¶")
            except:
                print(f"     æ—¶é—´é—´éš”: æ— æ³•è®¡ç®—")
    
    # æ—¶é—´åˆ†å¸ƒåˆ†æ
    print(f"\nğŸ“… é‡å¤æ–‡æœ¬çš„æ—¶é—´åˆ†å¸ƒ:")
    cursor.execute('''
        SELECT DATE(publish_time) as date, COUNT(*) as count
        FROM sentiment_results 
        WHERE duplication_rate > 0
        GROUP BY DATE(publish_time)
        ORDER BY date
    ''')
    
    date_distribution = cursor.fetchall()
    for date, count in date_distribution:
        print(f"  {date}: {count} æ¡é‡å¤æ–‡æœ¬")
    
    # å»ºè®®å’Œæ€»ç»“
    print(f"\nğŸ’¡ åˆ†æç»“è®ºå’Œå»ºè®®:")
    
    duplicate_ratio = duplicate_records / total_records if total_records > 0 else 0
    
    if duplicate_ratio < 0.05:
        print(f"  âœ… é‡å¤ç‡å¾ˆä½ ({duplicate_ratio*100:.1f}%)ï¼Œæ•°æ®è´¨é‡è‰¯å¥½")
    elif duplicate_ratio < 0.15:
        print(f"  âš ï¸  é‡å¤ç‡é€‚ä¸­ ({duplicate_ratio*100:.1f}%)ï¼Œå»ºè®®å…³æ³¨é‡å¤æ¥æº")
    else:
        print(f"  ğŸš¨ é‡å¤ç‡è¾ƒé«˜ ({duplicate_ratio*100:.1f}%)ï¼Œéœ€è¦åŠ å¼ºæ•°æ®æ¸…æ´—")
    
    if high_duplicate_records > 0:
        print(f"  ğŸ“Œ å‘ç° {high_duplicate_records} æ¡é«˜é‡å¤åº¦æ–‡æœ¬ï¼Œå»ºè®®æ£€æŸ¥:")
        print(f"     - æ˜¯å¦ä¸ºåŒä¸€äº‹ä»¶çš„ä¸åŒæŠ¥é“")
        print(f"     - æ˜¯å¦ä¸ºæ¨¡æ¿åŒ–å†…å®¹ï¼ˆå¦‚å…¬å‘Šã€æŠ¥å‘Šç­‰ï¼‰")
        print(f"     - æ˜¯å¦éœ€è¦åœ¨é‡‡é›†æ—¶è¿›è¡Œå»é‡")
    
    print(f"\nğŸ”§ æŠ€æœ¯å‚æ•°:")
    print(f"  - ç›¸ä¼¼åº¦é˜ˆå€¼: â‰¥75%")
    print(f"  - æ±‰æ˜è·ç¦»é˜ˆå€¼: â‰¤16")
    print(f"  - SimHashç®—æ³•: 64ä½ï¼Œçª—å£å¤§å°6")
    print(f"  - æ£€æµ‹ç²¾åº¦: é«˜ï¼ˆé¿å…è¯¯åˆ¤ï¼‰")
    
    conn.close()
    print(f"\næŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")

if __name__ == "__main__":
    generate_duplicate_analysis_report()

















